{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I perform additional processing of the SIMBA outputs for various datasets (10X) including the EHTM (bulk tissue) datasets. Some of the key steps include \n",
    "- adding taxonomic/lineage information \n",
    "- performing QC based on alignment length and percent identity of each hit\n",
    "- merging cell barcodes with those found in the Tabula Sapiens (TS) objects to get annotation data\n",
    "- formatting the TS objects such that cell type names are shortened and more neatly presented in subsequent figures\n",
    "- removed species found in negative controls from bulk tissue dataset. \n",
    "- will remove the contaminants for 10X dataset in a subsequent notebook. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Scanpy 1.5.1, on 2022-12-14 08:51.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "from matplotlib import cm\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import math\n",
    "import random\n",
    "from random import randrange\n",
    "import string\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import seaborn as sns\n",
    "\n",
    "cmap = sns.cm.rocket_r\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import anndata\n",
    "from anndata import read_h5ad\n",
    "from anndata import AnnData\n",
    "\n",
    "import scanpy as sc\n",
    "sc.logging.print_version_and_date()\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDir = '/oak/stanford/groups/quake/gita/raw/tab1_20200407/thirdAnalysis/10x/'\n",
    "mainDir2 = mainDir + 'analyze/'\n",
    "mainDir3 = '/oak/stanford/groups/quake/gita/raw/tab2_20200508/'\n",
    "mainDir4 = '/oak/stanford/groups/quake/gita/raw/tab2_20200508/tab2microbial/thirdAnalysis/'\n",
    "mainDir5 = '/oak/stanford/groups/quake/gita/raw/organ_20200204/secondAnalysis/'\n",
    "mainDir6 = '/oak/stanford/groups/quake/gita/raw/tab1_20200407/thirdAnalysis/analyze/'\n",
    "mainDir7 = '/oak/stanford/groups/quake/gita/raw/tab1_20200407/thirdAnalysis/'\n",
    "mainDir8 = '/oak/stanford/groups/quake/gita/raw/tab1_20200407/controlAnalysis/'\n",
    "mainDir9 = '/oak/stanford/groups/quake/gita/raw/organ_20191025/controlAnalysis/'\n",
    "mainDir10 = '/oak/stanford/groups/quake/gita/raw/tab3-14_20210420/all/'\n",
    "dbDir = '/oak/stanford/groups/quake/gita/raw/database/taxonomyNCBI20200125/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the ncbitax2lin tool, which you can use by activating the \"taxonomy\" conda environment (uses python 3.7): https://github.com/zyxue/ncbitax2lin\n",
    "This tool allows the conversion of taxon ids to lineages, and the output is saved as a dataframe. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (5,6,7,8,11,12,13,14,15,16,17,18,19,20,28,29,30,31,32,33,34,35,36,38,41,42,43,44,45,46,47,48,49,50,51,52,53,55,56,57,58,59,61,62,63,64,65,66,67,68,69,70) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tax = pd.read_csv(dbDir + 'ncbi_lineages_2021-01-26.csv')\n",
    "#want to take only the following columns from the lineage dataframe tax \n",
    "tax_short=tax[['tax_id','superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "takes in a dataframe and calculates based on fraction_complete how to bin different samples\n",
    "if it's 80% complete, then we can call that sample as done. \n",
    "\"\"\"\n",
    "\n",
    "def status(x):\n",
    "    if x ==0:\n",
    "        status='empty'\n",
    "    elif x<.80:\n",
    "        status='partial'\n",
    "    elif x>=.80:\n",
    "        status='done'\n",
    "    else:\n",
    "        status='not started'\n",
    "    \n",
    "    return(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a contamination blacklist for the EHTM dataset\n",
    "consisting of controls from the two sequencing runs I performed on tissues, bulk DNAseq. I have merged those tax_ids to create one taxid blacklist \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#getting unique taxids found in bulk DNA seq study of 10 donors (5 negative controls)\n",
    "negControl_tissue = pd.read_csv(mainDir9 + \"control_concatenated.tab\", delimiter='\\t')\n",
    "negControl_tissue.columns = ['seqName','refName','pathogen','bitscore','pident','evalue','gapopen','qstart','qend','sstart',\n",
    "'send','length','mismatch','staxids']\n",
    "negControl_tissue['tax_id'] = negControl_tissue['staxids'].apply(lambda x: int(str(x).split(';')[0]))\n",
    "\n",
    "#getting lineage information based on taxids\n",
    "negControl_tissue_lin=negControl_tissue.merge(tax_short, on='tax_id', how='left')\n",
    "negControl_tissue_lin['study']=['tissue']*negControl_tissue_lin.shape[0]\n",
    "\n",
    "\n",
    "#reading in all control reads and their lineages\n",
    "negControl_tissue_lin.to_csv(mainDir8 + 'tissue_controls_03192021.csv',index=False)\n",
    "\n",
    "#reading unique contaminating species\n",
    "negControl_tissue_lin_unique = negControl_tissue_lin.drop_duplicates(subset='species', keep='first')\n",
    "negControl_tissue_lin_unique.to_csv(mainDir8 + 'tissue_controls_uniqueSpecies_03192021.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading unique contaminating species\n",
    "tissue_controls=pd.read_csv(mainDir8 + 'tissue_controls_uniqueSpecies_03192021.csv')\n",
    "tissue_controls = tissue_controls[(tissue_controls['pident']>=90) & (tissue_controls['length']>=90)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Processing 10X TSP1 & TSP2, and EHTM SIMBA outputs (steps 1-8)\n",
    "the data is divided across virus blast, bacterial, and fungal branches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. reading the concatenated SIMBA output dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10X donor 1\n",
    "vir=pd.read_csv(mainDir + 'virNTblastn_concatenated.csv')\n",
    "#10x donor 2\n",
    "vir2 = pd.read_csv(mainDir4 + 'virNTblastn_concatenated.csv') \n",
    "#tissues (bulk dna sequencing)\n",
    "vir3 = pd.read_csv(mainDir5 + 'virNTblastn_concatenated.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "bac=pd.read_csv(mainDir + 'micoNT_blastn_concatenated.csv')\n",
    "bac2 = pd.read_csv(mainDir4 + 'micoNT_blastn_concatenated.csv')\n",
    "#tissues (bulk dna sequencing)\n",
    "bac3 = pd.read_csv(mainDir5 + 'micoNT_blastn_concatenated.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "fung=pd.read_csv(mainDir + 'fungi_NT_blastn_concatenated.csv')\n",
    "fung2=pd.read_csv(mainDir4 + 'fungi_NT_blastn_concatenated.csv')\n",
    "#tissues (bulk dna sequencing)\n",
    "fung3=pd.read_csv(mainDir5 + 'fungi_NT_blastn_concatenated.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the pre-filtered 10x dataset\n",
    "don1_10x=pd.concat([vir, bac, fung])\n",
    "don2_10x=pd.concat([vir2, bac2, fung2])\n",
    "prefil_10x = pd.concat([don1_10x,don2_10x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Getting lineage information based on taxids for 10x (donor 1 & 2) and EHTM validation (bulk DNA seq) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to take only the following columns from the lineage dataframe tax \n",
    "tax_short=tax[['tax_id','superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']]\n",
    "\n",
    "vir = vir.rename(columns={'staxids':'tax_id'})\n",
    "vir2 = vir2.rename(columns={'staxids':'tax_id'})\n",
    "vir3=vir3.rename(columns={'staxids':'tax_id'})\n",
    "\n",
    "bac = bac.rename(columns={'staxids':'tax_id'})\n",
    "bac2 = bac2.rename(columns={'staxids':'tax_id'})\n",
    "bac2.tax_id=bac2.tax_id.apply(lambda x: str(x).split(';')[0])\n",
    "bac2.tax_id = bac2.tax_id.astype('int64')\n",
    "bac3 = bac3.rename(columns={'staxids':'tax_id'})\n",
    "bac3.tax_id = bac3.tax_id.astype('int64')\n",
    "\n",
    "fung =fung.rename(columns={'staxids':'tax_id'})\n",
    "fung2 = fung2.rename(columns={'staxids':'tax_id'})\n",
    "fung3 = fung3.rename(columns={'staxids':'tax_id'})\n",
    "\n",
    "fung.tax_id = fung.tax_id.apply(lambda x: str(x).split(';')[0])\n",
    "fung2.tax_id=fung2.tax_id.apply(lambda x: str(x).split(';')[0])\n",
    "fung3.tax_id=fung3.tax_id.apply(lambda x: str(x).split(';')[0])\n",
    "\n",
    "\n",
    "fung.tax_id = fung.tax_id.astype('int64')\n",
    "fung2.tax_id = fung2.tax_id.astype('int64')\n",
    "fung3.tax_id = fung3.tax_id.astype('int64')\n",
    "\n",
    "#merging the  dataframe (for which we have taxid and merging it with tax_short for lineage informatin)\n",
    "vir_lin=vir.merge(tax_short, on='tax_id', how='left')\n",
    "vir_lin2=vir2.merge(tax_short, on='tax_id', how='left')\n",
    "vir_lin3=vir3.merge(tax_short, on='tax_id', how='left')\n",
    "\n",
    "bac_lin=bac.merge(tax_short, on='tax_id', how='left')\n",
    "bac_lin2=bac2.merge(tax_short, on='tax_id', how='left')\n",
    "bac_lin3=bac3.merge(tax_short, on='tax_id', how='left')\n",
    "\n",
    "fung_lin=fung.merge(tax_short, on='tax_id', how='left')\n",
    "fung_lin2=fung2.merge(tax_short, on='tax_id', how='left')\n",
    "fung_lin3=fung3.merge(tax_short, on='tax_id', how='left')\n",
    "\n",
    "\n",
    "don1_10x_prefil=pd.concat([vir_lin, bac_lin, fung_lin])\n",
    "don2_10x_prefil=pd.concat([vir_lin2, bac_lin2, fung_lin2])\n",
    "prefil_10x_withLineage = pd.concat([don1_10x_prefil,don2_10x_prefil])\n",
    "\n",
    "prefil_10x_withLineage.to_csv(mainDir + 'don1_don2_10x_blastn_nt_pre_filteration_withLineage.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. concatenating viral bacterial and fungal dataframes for don1, don2 (both 10x), and EHTM validation dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "don1_10x=pd.concat([vir_lin, bac_lin, fung_lin])\n",
    "don2_10x=pd.concat([vir_lin2, bac_lin2, fung_lin2])\n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. eliminating the contamination species for the EHTM bulk tissue controls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tissue_controls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-a62c8136d85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtis_19\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvir_lin3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbac_lin3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfung_lin3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtis_19_cont_free\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtis_19\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtis_19\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtissue_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tissue_controls' is not defined"
     ]
    }
   ],
   "source": [
    "tis_19=pd.concat([vir_lin3, bac_lin3, fung_lin3])\n",
    "\n",
    "tis_19_cont_free = tis_19[~tis_19['species'].isin(tissue_controls.species.to_list())]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. taking only reads from viruses, bacteria, and fungi along with more reformatting steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "don1_10x_fil2 = don1_10x_prefil[(don1_10x_prefil['superkingdom'].str.contains('Bacteria|Viruses', case=False)) | \n",
    "                 (don1_10x_prefil['phylum'].str.contains('mycota', case=False))] \n",
    "\n",
    "don2_10x_fil2 = don2_10x_prefil[(don2_10x_prefil['superkingdom'].str.contains('Bacteria|Viruses', case=False)) | \n",
    "                 ( don2_10x_prefil['phylum'].str.contains('mycota', case=False))] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "tis_19_cont_free_fil2 = tis_19_cont_free[(tis_19_cont_free['superkingdom'].str.contains('Bacteria|Viruses', case=False)) | \n",
    "                 ( tis_19_cont_free['phylum'].str.contains('mycota', case=False))] \n",
    "tis_19_cont_free_fil2['donor'] = tis_19_cont_free_fil2['sample'].apply(lambda x: x.split('_')[0])\n",
    "tis_19_cont_free_fil2['tissue'] = tis_19_cont_free_fil2['sample'].apply(lambda x: x.split('_')[1])\n",
    "tis_19_cont_free_fil2['fraction'] = tis_19_cont_free_fil2['sample'].apply(lambda x: x.split('_')[2])\n",
    "tis_19_cont_free_fil2['sample2'] = tis_19_cont_free_fil2['donor']+ '_' + tis_19_cont_free_fil2['tissue']\n",
    "tis_19_cont_free_fil2 = tis_19_cont_free_fil2[~tis_19_cont_free_fil2['sample'].str.contains('control|hood_water')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "don1_10x_fil2['cell'] = don1_10x_fil2.seqName.apply(lambda x: x.split('_')[1])\n",
    "don1_10x_fil2['umi'] = don1_10x_fil2.seqName.apply(lambda x: x.split('_')[2])\n",
    "\n",
    "don2_10x_fil2['cell'] = don2_10x_fil2.seqName.apply(lambda x: x.split('_')[1])\n",
    "don2_10x_fil2['umi'] = don2_10x_fil2.seqName.apply(lambda x: x.split('_')[2])\n",
    "\n",
    "\n",
    "don1_10x_fil2['don'] = ['don1'] * don1_10x_fil2.shape[0]\n",
    "don2_10x_fil2['don'] = ['don2'] * don2_10x_fil2.shape[0]\n",
    "\n",
    "blastdb_don1and2=pd.concat([don1_10x_fil2, don2_10x_fil2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let's get rid of any possible duplicates (multiple hits for the same query sequence.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blastdb_don1and2.shape[0])\n",
    "blastdb_don1and2 = blastdb_don1and2.drop_duplicates('seqName')\n",
    "print(blastdb_don1and2.shape[0])\n",
    "#dataframe size is reduced from 839049 to 838047"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets load and clean up 10X TSP1 and TSP2 objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and modifying 10X TSP1 and TSP2 objects\n",
    "tsp1and2_10x = sc.read_h5ad(mainDir3 +'objects/totalVelo_withCellCycleScores_mitoUnfiltered_Dec2020.h5ad')\n",
    "\n",
    "tsp1and2_10x.obs = tsp1and2_10x.obs.reset_index()\n",
    "tsp1and2_10x.obs.rename(columns={'X10X_barcode':'cell', 'compartment_pred':'compartment',\n",
    "                                 'Propagated.Annotation':'celltype', 'X10X_run':'sample'}, inplace=True)\n",
    "\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype']\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('double-positive, alpha-beta thymocyte','alpha-beta thymocyte')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD4-positive, alpha-beta T cell','CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell of artery','artery endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell of vascular tree','vascular endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD8-positive, alpha-beta T cell','CD8+, T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell of lymphatic vessel','lymph endo.c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('vein endothelial cell','vein endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD4-positive, alpha-beta T cell','naive CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('skeletal muscle satellite stem cell','skeletal muscle stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD4+ T cell','naive CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('capillary endothelial cell','endo. capillary c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell','endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] = tsp1and2_10x.obs['celltype2'].apply(lambda x: x.replace('cell', 'c.'))\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD8-alpha-alpha-positive, alpha-beta intraepithelial T c.','CD8+ intraepithelial T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD4-positive, CD25-positive, alpha-beta regulatory T c.','CD4+ CD25+ reg. T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD4-positive, alpha-beta cytotoxic T c','CD4+ CD25+ cytotoxic T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD34-positive, CD38-negative multipotent progenitor c.','CD34+ CD38- multipotent T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('intestinal secretory progenitor','intestinal secr. prog.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('intestinal transient amplifying c.','intestinal trans. ampl. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('intestinal crypt stem c. distal','intestinal crypt stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('intestinal crypt stem c. proximal','intestinal crypt stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('medullary thymic epithelial c.','medullary thymic epi. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('vascular associated smooth muscle c.','vasc. smooth muscle c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('skeletal muscle stem c. 3','skeletal muscle stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('skeletal muscle stem c. 2','skeletal muscle stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('skeletal muscle stem c. 1','skeletal muscle stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('skeletal muscle stem c. 4','skeletal muscle stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('mesenchymal stem c. 1','mesenchymal stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('mesenchymal stem c. 2','mesenchymal stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('epithelial c. of alveolus of lung','lung alveolus epi. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('myeloid dendritic c., human','myeloid dendritic c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD4+ T c.','naive CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD4-positive, alpha-beta memory T c.','CD4+ memory T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('plasmacytoid dendritic c., human','plasmacytoid dendritic c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('smooth muscle c. 1','smooth muscle c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('smooth muscle c. 2','smooth muscle c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('smooth muscle c. 3','smooth muscle c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('pericyte c. 3','pericyte c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('pericyte c. 2','pericyte c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('pericyte c. 1','pericyte c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('activated CD8+, T c., human','activated CD8+, T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('serous c. of epithelium of bronchus','bronchus epi. serous c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD8-positive, alpha-beta memory T c.','CD8+ memory T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD4+ T c.','naive CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('pericyte c. 4','pericyte c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('mesenchymal c. 3','mesenchymal c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('mesenchymal c. 1','mesenchymal c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('mesenchymal c. 2','mesenchymal c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('mesenchymal stem c. 3','mesenchymal stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('macrophage 2','macrophage')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('macrophage 1','macrophage')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('group 3 innate lymphoid c.','lymphoid c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD4-positive helper T c.','CD4+ helper T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD8+, T c.','naive CD8+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD4+ T c.','naive CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('dendritic c., human','dendritic c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('activated CD8+, T c., human', 'activated CD8+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD8+, T c.','CD8+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD4+ CD25+ cytotoxic T c..','CD4+ CD25+ cytotoxic T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].apply(lambda x: x.replace(',',''))\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].apply(lambda x: x.replace('thymus-derived',' '))\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('double-positive, alpha-beta thymocyte','alpha-beta thymocyte')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD4-positive, alpha-beta T cell','CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell of artery','artery endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell of vascular tree','vascular endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('CD8-positive, alpha-beta T cell','CD8+, T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell of lymphatic vessel','lymph endo.c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('vein endothelial cell','vein endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD4-positive, alpha-beta T cell','naive CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('skeletal muscle satellite stem cell','skeletal muscle stem c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('naive thymus-derived CD4+ T cell','naive CD4+ T c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('capillary endothelial cell','endo. capillary c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].str.replace('endothelial cell','endo. c.')\n",
    "tsp1and2_10x.obs['celltype2'] =tsp1and2_10x.obs['celltype2'].apply(lambda x: x.replace('cell', 'c.'))\n",
    "tsp1and2_10x.obs['tissue'] =tsp1and2_10x.obs['tissue'].apply(lambda x: x.replace('PancreasExocrine', 'Pancreas'))\n",
    "tsp1and2_10x.obs['tissue'] =tsp1and2_10x.obs['tissue'].apply(lambda x: x.replace('PancreasEndocrine', 'Pancreas'))\n",
    "\n",
    "\n",
    "tsp1and2_10x.obs['log2_n_genes']= np.log2(tsp1and2_10x.obs['n_genes'])\n",
    "tsp1and2_10x.obs['log2_n_counts']= np.log2(tsp1and2_10x.obs['n_counts'])\n",
    "comp=tsp1and2_10x.obs['compartment'].iloc[:,1].tolist()\n",
    "tsp1and2_10x.obs['compartment2']= comp\n",
    "tsp1and2_10x.obs.drop(columns=['compartment'],inplace=True)\n",
    "tsp1and2_10x = tsp1and2_10x[~tsp1and2_10x.obs['compartment2'].str.contains('PNS')]\n",
    "\n",
    "\n",
    "tsobj_don1and2=tsp1and2_10x.obs[['cell','tissue','log2_n_counts','n_counts', 'log2_n_genes','n_genes', 'celltype2',\n",
    "                                 'compartment2','donor','decision','sample']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting together BLAST dataframe (blastdb_don1and2) and TS object (tsobj_don1and2) donors 1 and 2\n",
    "There are three categories for the merged blast outputs (blastdb_don1and2) and TS object (tsobj_don1and2). \\\n",
    "**1) intra** --> annotated cells that have significant **intra**cellular hits \\\n",
    "**2) nothing** --> annotated cells that don't have any significant intracellular hits (based on evalue) \\\n",
    "**3) extra** --> significant hits that are found in either found **extra**cellularly or in unannotated cells. i.e. associated with cellular barcodes. \n",
    "\n",
    "how many of each category is in the dataset (prior to removal of contamination?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of annotated cells that have significant microbial hits (based on e-value < 10^-5, no other filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24351"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_cells_with_hits = tsobj_don1and2[tsobj_don1and2['cell'].isin(blastdb_don1and2['cell'].tolist())]\n",
    "ann_cells_with_hits.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total number of annotated cells & fraction of total annotated cells with a hit. **14% of annotated cells had a sig. hit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of annotated cells (donor 1 and 2):  175489\n",
      "fraction of total annotated cells with a hit  (donor 1 and 2):  0.14\n"
     ]
    }
   ],
   "source": [
    "print ('total number of annotated cells (donor 1 and 2): ', tsobj_don1and2['cell'].nunique())\n",
    "\n",
    "print ('fraction of total annotated cells with a hit  (donor 1 and 2): ', np.round(ann_cells_with_hits.shape[0]/tsobj_don1and2['cell'].nunique(),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are the hits **(56k)** found in annotated cells - thus **intra**cellular hits, coming from **24K cells**. see above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "intra_don1and2=blastdb_don1and2[blastdb_don1and2['cell'].isin(tsobj_don1and2['cell'].tolist())]\n",
    "print(intra_don1and2.shape[0])\n",
    "\n",
    "intra_don1and2['hit']=['yes']* intra_don1and2.shape[0]\n",
    "intra_don1and2['hit_type']=['intra']* intra_don1and2.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are hits that are NOT found in annotated cells - thus **extra**cellular hits. 7% of total hits are associated with annotated cells. Others are extracellular or from unannotated cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "extra_don1and2 = blastdb_don1and2[~blastdb_don1and2['cell'].isin(tsobj_don1and2['cell'].tolist())]\n",
    "print(extra_don1and2.shape[0])\n",
    "\n",
    "extra_don1and2['hit']=extra_don1and2.shape[0]*['yes']\n",
    "extra_don1and2['hit_type']=extra_don1and2.shape[0]*['extra']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07\n"
     ]
    }
   ],
   "source": [
    "print(np.round(intra_don1and2.shape[0]/extra_don1and2.shape[0],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are the annotated cells with **nothing** detected inside. There are about 150K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "nothing_don1and2 = tsobj_don1and2[~tsobj_don1and2['cell'].isin(blastdb_don1and2['cell'].tolist())]\n",
    "print(nothing_don1and2.shape[0])\n",
    "\n",
    "nothing_don1and2['hit']=['no']* nothing_don1and2.shape[0]\n",
    "nothing_don1and2['hit_type']=['none']* nothing_don1and2.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets put together these different pieces now that they have labels with which we can seperate them out again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "blhits=pd.concat([extra_don1and2, intra_don1and2])\n",
    "fin=blhits.merge(nothing_don1and2, on=['cell','hit_type', 'hit', 'sample'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sanity check on the final joint dataframe. Note hit will be no, if the row is of a cell that doesn't have a hit. That cell will get hit type =='none'. If hit=='yes', then it is either from an annotated cell hit_type=='intra' or 'extra' if it comes from an unannotated cell or empty droplet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    838047\n",
       "no     152799\n",
       "Name: hit, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin['hit'].value_counts(dropna=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extra    781284\n",
       "none     152799\n",
       "intra     56763\n",
       "Name: hit_type, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin['hit_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the number of unique hits that are found in annotated cells (category intra):  56763\n",
      "these are the number of unique umis that are found in annotated cells (category intra):  27768\n",
      "number of annotated cells (unique cell barcodes) that have significant hits:  23967\n"
     ]
    }
   ],
   "source": [
    "print('these are the number of unique hits that are found in annotated cells (category intra): ', intra_don1and2.seqName.nunique())\n",
    "print('these are the number of unique umis that are found in annotated cells (category intra): ', intra_don1and2.umi.nunique())\n",
    "print('number of annotated cells (unique cell barcodes) that have significant hits: ', intra_don1and2.cell.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is already donor information under the heading 'don' but not under 'donor'. these two columns need to be consolidated. Need to make sure i can do apply for nan values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin['cell_bc'] = fin['cell'].apply(lambda x: x+'-1')\n",
    "e = fin[fin['hit']=='yes']\n",
    "no = fin[fin['hit']=='no']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting tissue & donor information for the blast df based on sample name. The ts object already has this information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# fin['cell_bc'] = fin['cell'].apply(lambda x: x+'-1')\n",
    "e['sample'] = e['sample'].apply(lambda x: x.split('_L0')[0])\n",
    "e['donor'] = e['sample'].apply(lambda x: x.split('_')[0])\n",
    "e['tissue'] = e['sample'].apply(lambda x: x.split('_')[1]).apply(lambda x: x.lower())\n",
    "\n",
    "#matching tissue names (can't find heart in TS object but i see it in blast dataframe from sample name - wonder if it is a misannotation)\n",
    "no['tissue'] = no['tissue'].apply(lambda x: x.lower())\n",
    "no['tissue'] = no['tissue'].apply(lambda x: x.replace('small_intestine', 'si'))\n",
    "no['tissue'] = no['tissue'].apply(lambda x: x.replace('large_intestine', 'li'))\n",
    "no['tissue'] = no['tissue'].apply(lambda x: x.replace('bone_marrow', 'bm'))\n",
    "e['tissue'] = e['tissue'].apply(lambda x: x.replace('exopancreas2', 'pancreas'))\n",
    "e['tissue'] = e['tissue'].apply(lambda x: x.replace('exopancreas1', 'pancreas'))\n",
    "e['tissue'] = e['tissue'].apply(lambda x: x.replace('endopancreas', 'pancreas'))\n",
    "e['tissue'] = e['tissue'].apply(lambda x: x.replace('lymphnode', 'lymph_node'))\n",
    "\n",
    "\n",
    "fin2=pd.concat([e, no])\n",
    "\n",
    "#interstingly tabula sapiens doesn't have umi information\n",
    "fin2['compartment']= fin2['compartment2']\n",
    "\n",
    "fin2['cell']= fin2['cell'] + '_' + fin2['sample']\n",
    "\n",
    "fin2 = fin2.drop(columns={'Unnamed: 0', 'duplicates', 'operation','blast', 'source', 'db', 'gapopen', 'don', 'mismatch','compartment2'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving don1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin2.to_csv(mainDir + 'don1_don2_10x_12_08_2022-postreview2022.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column name explanation final dataframe (donor 1 and 2) \n",
    "- Blast dataframe columns:\n",
    "    - **seqName**: e.g. A00111:327:HL57HDSXX:4:1202:22941:23719_TAGGTCAGAGACATCA_AGAAATAACGCC\n",
    "    - **seq**: microbial sequence \n",
    "    - **refName**: the BLAST subject reference gi|1862738216|gb|CP055292.1| \n",
    "    - **pathogen**: common name of the hit Shigella sonnei strain SE6-1 chromosome, complete genome\n",
    "    - **bitscore**: see BLAST tutorial\n",
    "    - **pident**: percent identity between subject and query\n",
    "    - **evalue**: see BLAST tutorial\n",
    "    - **qstart**: query start position\n",
    "    - **qend**: query end position\n",
    "    - **sstart**: subject start position\n",
    "    - **send**: subject end position\n",
    "    - **length**: length of the alignment between subject and query\n",
    "    - taxonomy columns\n",
    "        - **tax_id**: taxonomic id with which we can get the following taxonomic categories\n",
    "        - **superkingdom**\n",
    "        - **phylum**\n",
    "        - **class**\n",
    "        - **order**\n",
    "        - **family**\n",
    "        - **genus**\n",
    "        - **species**\n",
    "\n",
    "    - **sample**: TSP1_endopancreas_3_S3\n",
    "    - **umi**: AGAAATAACGCC \n",
    "\n",
    "\n",
    "- TS object columns (blast dataframe does not produce these on its own)\n",
    "    - **n_counts**: number of reads per cell\n",
    "    - **n_genes**: number of genes per cell\n",
    "    - **log2_n_counts**: log2 of n_counts\n",
    "    - **log2_n_genes**: log2 of n_genes\n",
    "    - **compartment**: e.g. immune, epithelial\n",
    "    - **celltype2**: cell type\n",
    "\n",
    "\n",
    "- Shared columns:\n",
    "    - **cell**: cell barcode e.g. CATATTCCAAAGCGGT_TSP2_Thymus_NA_10X_1_4_5prime_S33\n",
    "    - **cell_bc**: cell barcode with \"-1\" appended to it. e.g. CATATTCCAAAGCGGT-1 \n",
    "    - **hit**: the column with which to seperate out the dataframe into blast (hit=='yes') and ts object (hit=='no')\n",
    "    - **hit_type**: tells us whether the hit comes from an annotated cell (hit_type=='intra'), unannotated cell ('extra') or no hit ('none')\n",
    "    - **tissue**: tissue type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the EHTM dataset (bulk DNA seq )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tis = pd.read_csv(mainDir + 'bulk_tissues_blastn_nt_naPhylaNotFiltered_03_12_2021.csv')\n",
    "#additionally getting rid of some of the other common contaminants in our lab\n",
    "tis = tis[~tis['species'].str.contains('Ralstonia|Sphingomonas|Variovorax|Hathewaya histolytica', case=False, na=False)]\n",
    "tis_filt=tis[(tis['length']>=90) & (tis['pident']>=90)] \n",
    "tis_filt.to_csv(mainDir + 'bulk_tissues_blastn_nt_naPhylaNotFiltered_11_30_2021.csv', index=False) #no change here in post-review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Processing 10x TSP3-16 SIMBA outputs\n",
    "you can skip to the next section (section 10 \"start here\") , since results are saved. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of those reads can be read from the completed files in the NT folders and others need to be grabbed from the batched results. \n",
    "\n",
    "Note batch files are different because they will have the name of the file they came from as part of their sequence id, whereas unbatched regular file outputs will not. They need to be matched before they are combined. I will do this by modifying the batch files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to take only the following columns from the lineage dataframe tax \n",
    "tax_short=tax[['tax_id','superkingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling in data from the batched data files first (bacteria) \n",
    "#column headers\n",
    "cols =['seqName', 'refName', 'pathogen', 'bitscore', 'pident', 'evalue', 'gapopen', 'qstart', 'qend', 'sstart', 'send', 'length', 'mismatch', 'tax_id']\n",
    "bact_batch =pd.DataFrame({})\n",
    "\n",
    "for file in glob.glob(mainDir10 + 'batchedFiles/bacteria/batched/micoNT_blastn/*.tab'):\n",
    "    #looking at non empty files \n",
    "    if os.path.getsize(file)>0:\n",
    "        #getting the batch number \n",
    "        batch = file.split('/')[-1].split('.tab')[0]\n",
    "        \n",
    "        df=pd.read_csv(file, delimiter='\\t')\n",
    "        df.columns=cols\n",
    "        df['sample'] = df.seqName.apply(lambda x: x.split('-')[1])\n",
    "        df['seqName'] = df.seqName.apply(lambda x: x.split('-')[0])\n",
    "        df['batch']=df.shape[0]*[batch]\n",
    "        df['filepath']=df.shape[0]*[file]\n",
    "        \n",
    "        df['tax_id']=df['tax_id'].apply(lambda x: str(x).split(';')[0])\n",
    "        df.tax_id = df.tax_id.astype('int64')\n",
    "        #adding lineage information\n",
    "        df=df.merge(tax_short, on='tax_id', how='left')\n",
    "        #filtering df to contain only bacteria, viruses, archaea, fungi & blastocyst\n",
    "        df = df[(df['superkingdom'].str.contains('Bacteria|Viruses|Archaea', case=False) | \n",
    "                  df['phylum'].str.contains('mycota', case=False) |\n",
    "                  df['species'].str.contains('Blastocyst',case=False)==True)] \n",
    "        \n",
    "    bact_batch = pd.concat([bact_batch, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### viruses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling in data from the batched data files first (viruses)\n",
    "#column headers\n",
    "cols =['seqName', 'refName', 'pathogen', 'bitscore', 'pident', 'evalue', 'gapopen', 'qstart', 'qend', 'sstart', 'send', 'length', 'mismatch', 'tax_id']\n",
    "virus_batch =pd.DataFrame({})\n",
    "\n",
    "for file in glob.glob(mainDir10 + 'batchedFiles/viruses/batched/virusNT_blastn/*.tab'):\n",
    "    #looking at non empty files \n",
    "    if os.path.getsize(file)>0:\n",
    "        #getting the batch number \n",
    "        batch = file.split('/')[-1].split('.tab')[0]\n",
    "        \n",
    "        df=pd.read_csv(file, delimiter='\\t')\n",
    "        df.columns=cols\n",
    "        df['sample'] = df.seqName.apply(lambda x: x.split('-')[1])\n",
    "        df['seqName'] = df.seqName.apply(lambda x: x.split('-')[0])\n",
    "        df['batch']=df.shape[0]*[batch]\n",
    "        df['filepath']=df.shape[0]*[file]\n",
    "        \n",
    "        df['tax_id']=df['tax_id'].apply(lambda x: str(x).split(';')[0])\n",
    "        df.tax_id = df.tax_id.astype('int64')\n",
    "        #adding lineage information\n",
    "        df=df.merge(tax_short, on='tax_id', how='left')\n",
    "        #filtering df to contain only bacteria, viruses, archaea, fungi & blastocyst\n",
    "        df = df[(df['superkingdom'].str.contains('Bacteria|Viruses|Archaea', case=False) | \n",
    "                  df['phylum'].str.contains('mycota', case=False) |\n",
    "                  df['species'].str.contains('Blastocyst',case=False)==True)] \n",
    "    virus_batch = pd.concat([virus_batch, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fungi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling in data from the batched data files first (fungi) \n",
    "#column headers\n",
    "cols =['seqName', 'refName', 'pathogen', 'bitscore', 'pident', 'evalue', 'gapopen', 'qstart', 'qend', 'sstart', 'send', 'length', 'mismatch', 'tax_id']\n",
    "fungi_batch =pd.DataFrame({})\n",
    "\n",
    "for file in glob.glob(mainDir10 + 'batchedFiles/fungi/batched/fungiNT_blastn/*.tab'):\n",
    "    #looking at non empty files \n",
    "    if os.path.getsize(file)>0:\n",
    "        #getting the batch number \n",
    "        batch = file.split('/')[-1].split('.tab')[0]\n",
    "        \n",
    "        df=pd.read_csv(file, delimiter='\\t')\n",
    "        df.columns=cols\n",
    "        df['sample'] = df.seqName.apply(lambda x: x.split('-')[1])\n",
    "        df['seqName'] = df.seqName.apply(lambda x: x.split('-')[0])\n",
    "        df['batch']=df.shape[0]*[batch]\n",
    "        df['filepath']=df.shape[0]*[file]\n",
    "        \n",
    "        df['tax_id']=df['tax_id'].apply(lambda x: str(x).split(';')[0])\n",
    "        df.tax_id = df.tax_id.astype('int64')\n",
    "        #adding lineage information\n",
    "        df=df.merge(tax_short, on='tax_id', how='left')\n",
    "        #filtering df to contain only bacteria, viruses, archaea, fungi & blastocyst\n",
    "        df = df[(df['superkingdom'].str.contains('Bacteria|Viruses|Archaea', case=False) | \n",
    "                  df['phylum'].str.contains('mycota', case=False) |\n",
    "                  df['species'].str.contains('Blastocyst',case=False)==True)] \n",
    "    fungi_batch = pd.concat([fungi_batch, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenating all batched (currently partial) blast outputs from fungi, viruses, and bacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batched=pd.concat([bact_batch, virus_batch, fungi_batch])\n",
    "\n",
    "all_batched.to_csv(mainDir10 + 'all_batched_09_09_2021.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I also want to read the previously unbatched SIMBA outputs\n",
    "need to know which jobs weren't batched because they were already complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the status of jobs from a previous file\n",
    "maindf_all=pd.read_csv(mainDir10 + 'status_of_nt_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the samples\n",
    "samples=maindf_all[maindf_all['operation']=='humanFiltered'].file.unique().tolist()\n",
    "samples_df=pd.DataFrame(samples, columns=['file'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually getting the status of each job based on fraction of blast that's complete\n",
    "maindf_vir = maindf_all[maindf_all['operation']=='virNTblastn']\n",
    "maindf_vir = maindf_vir.merge(samples_df, on='file', how='outer') \n",
    "maindf_vir['status_vir'] = maindf_vir['frac_complete'].apply(lambda x: status(x))\n",
    "\n",
    "maindf_bac = maindf_all[maindf_all['operation']=='micoNT_blastn']\n",
    "maindf_bac = maindf_bac.merge(samples_df, on='file', how='outer') \n",
    "maindf_bac['status_bact'] = maindf_bac['frac_complete_bact'].apply(lambda x: status(x))\n",
    "\n",
    "maindf_fun = maindf_all[maindf_all['operation']=='fungi_NT_blastn']\n",
    "maindf_fun = maindf_fun.merge(samples_df, on='file', how='outer') \n",
    "maindf_fun['status_fun'] = maindf_fun['frac_complete_fun'].apply(lambda x: status(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of complete files: 193\n"
     ]
    }
   ],
   "source": [
    "#now just collecting all the filepaths to the files that were more than 80% done. \n",
    "maindf_vir_done = maindf_vir[maindf_vir['status_vir']=='done']\n",
    "maindf_bac_done = maindf_bac[maindf_bac['status_bact']=='done']\n",
    "maindf_fun_done = maindf_fun[maindf_fun['status_fun']=='done']\n",
    "fps1 = maindf_vir_done.filepath.tolist()\n",
    "fps2 = maindf_bac_done.filepath.tolist()\n",
    "fps3 = maindf_fun_done.filepath.tolist()\n",
    "#list of file paths to nt blast jobs from the three kingdoms that are complete\n",
    "fps=fps1 + fps2 + fps3\n",
    "print('number of complete files:', len(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column headers\n",
    "cols =['seqName', 'refName', 'pathogen', 'bitscore', 'pident', 'evalue', 'gapopen',\n",
    "       'qstart', 'qend', 'sstart', 'send', 'length', 'mismatch', 'tax_id']\n",
    "all_unbatched =pd.DataFrame({})\n",
    "\n",
    "for file in fps:\n",
    "    #looking at non empty files \n",
    "    if os.path.getsize(file)>0:\n",
    "        #getting the batch number \n",
    "        filename = file.split('/')[-1].split('.tab')[0]\n",
    "        \n",
    "        df=pd.read_csv(file, delimiter='\\t')\n",
    "        df.columns=cols\n",
    "        df['sample'] = df.shape[0]*[filename]\n",
    "        df['batch']=df.shape[0]*['unbatched']\n",
    "        df['filepath']=df.shape[0]*[file]\n",
    "        \n",
    "        df['tax_id']=df['tax_id'].apply(lambda x: str(x).split(';')[0])\n",
    "        df.tax_id = df.tax_id.astype('int64')\n",
    "        #adding lineage information\n",
    "        df=df.merge(tax_short, on='tax_id', how='left')\n",
    "        #filtering df to contain only bacteria, viruses, archaea, fungi and blastocyst\n",
    "        \n",
    "        df = df[(df['superkingdom'].str.contains('Bacteria|Viruses|Archaea', case=False) | \n",
    "                          df['phylum'].str.contains('mycota', case=False) |\n",
    "                          df['species'].str.contains('Blastocyst',case=False)==True)]\n",
    "        \n",
    "    all_unbatched = pd.concat([all_unbatched, df])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unbatched.to_csv(mainDir10 + 'all_unbatched_09_09_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenating all batched and unbatched SIMBA outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the processed SIMBA outputs of all the batched files for blast against NT through the fungal, viral, and bacterial branches\n",
    "all_batched=pd.read_csv(mainDir10 + 'all_batched_09_09_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the processed SIMBA outputs of all the unbatched files for blast against NT through the fungal, viral, and bacterial branches\n",
    "all_unbatched=pd.read_csv(mainDir10 + 'all_unbatched_09_09_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.concat([all_unbatched, all_batched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a total of 1533950 top hits were found in after BLASTING files from TSP3-16 with E-values < 10^-5\n"
     ]
    }
   ],
   "source": [
    "print('a total of ' + str(final.shape[0]) + ' top hits were found in after BLASTING files from TSP3-16 with E-values < 10^-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this step is done to match the TS 10x object\n",
    "final['sample_short']= final['sample'].apply(lambda x: '_'.join(x.split('_')[:-2]))\n",
    "\n",
    "#also reading out the cell barcode and umi from the seq name\n",
    "final['cell_bc'] = final['seqName'].apply(lambda x: x.split('_')[1])\n",
    "final['umi'] = final['seqName'].apply(lambda x: x.split('_')[2])\n",
    "final['cell_bc_umi'] = final['seqName'].apply(lambda x: '_'.join(x.split('_')[1:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donors 3,4 and 5 had sample names that were different across fastq files and TS object. \n",
    "other donors are fine, except for donor 14 where there is an extra '_1' added to some samples it seems, which I will correct in the SIMBA output so that they can be merged properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#donor 5\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP5_Eye1_062920', 'TSP5_Eye_NA_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP5_Eye2_062920', 'TSP5_Eye_NA_10X_1_2')\n",
    "#donor 4\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP4_Mammary1_062920', 'TSP4_Mammary_NA_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP4_Mammary2_062920', 'TSP4_Mammary_NA_10X_1_2')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP4_Myometrium_062920', 'TSP4_Uterus_Myometrium_10X_1_1')\n",
    "#donor 3\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP3_Eye_062620', 'TSP3_Eye_LacrimalGland_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP3_Eye2_062620', 'TSP3_Eye_NA_10X_1_1_NoCornea')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP3_Eye3_062620', 'TSP3_Eye_Conjunctiva_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP3_Eye4_062620', 'TSP3_Eye_Orbital_10X_1_1')\n",
    "#donor 14\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Bladder_NA_10X_1', 'TSP14_Bladder_NA_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Blood_NA_10X_1', 'TSP14_Blood_NA_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_LI_Distal_10X_1', 'TSP14_LI_Distal_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Muscle_Abdomen_10X_1', 'TSP14_Muscle_Abdomen_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Muscle_Diaphragm_10X_1', 'TSP14_Muscle_Diaphragm_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Skin_Abdomen_10X_1', 'TSP14_Skin_Abdomen_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Skin_Chest_10X_1', 'TSP14_Skin_Chest_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Spleen_NA_10X_1', 'TSP14_Spleen_NA_10X_1_1')\n",
    "final['sample_short']=final['sample_short'].str.replace('TSP14_Tongue_Posterior_10X_1', 'TSP14_Tongue_Posterior_10X_1_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this step is done to match the TS 10x object\n",
    "\n",
    "final['cell'] = final['cell_bc'] + '_' +final['sample_short']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(mainDir10 + 'all_batched_and_unbatched_09_09_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NNTR: just open the obs layer as a dataframe once these pre-processing steps have been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10x tabula sapiens object\n",
    "alldons = sc.read_h5ad(mainDir3 + 'objects/tSP1_TSP15_scvi_donor-method_normalized-log1p-scaled_annotated_withCellcycle.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just renaming columns and doing some filtering of the 10x object, to include only 10x sequenced cells, and donors 3-15 (16 was not yet available so we have BLAST results but no cell identity info for that donor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    }
   ],
   "source": [
    "# get rid of info-poor columns in the object\n",
    "# get the cell barcode in a format that would be the same between the 10x object and SIMBA output dataframe, called cell_bc2\n",
    "\n",
    "alldons_10x = alldons[alldons.obs['method']=='10X']\n",
    "\n",
    "alldons_10x.obs['sample'] = alldons_10x.obs['cell_identifier'].apply(lambda x: '_'.join(x.split('_')[1:]))\n",
    "#dropping some columns that are not important\n",
    "alldons_10x.obs.drop(columns={'cell_identifier','10X_run', 'pilot', 'subtissue', '10X_sample', '10X_replicate', 'cDNAplate', \n",
    "                               'libraryplate', 'well', 'score_epithelial', 'score_endothelial', 'score_stromal','score_immune',\n",
    "                                '_scvi_batch', '_scvi_labels', '_scvi_local_l_mean','_scvi_local_l_var', '_dataset',\n",
    "                                'knn_on_bbknn_pred','knn_on_scanorama_pred','decontX_split', 'consensus_percentage',\n",
    "                                'consensus_prediction', '_labels_annotation', 'scanvi_offline_pred', 'svm_pred', \n",
    "                               '_labels_annotation', '_batch_annotation','onclass_pred', 'rf_pred', '_ref_subsample',\n",
    "                               'knn_on_scvi_offline_pred'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming some columns\n",
    "alldons_10x.obs = alldons_10x.obs.rename(columns={'cell_ontology_class':'celltype', \n",
    "                          'computational_compartment_assignment':'compartment', 'sample': 'sample2'})\n",
    "alldons_10x.obs.drop(columns={'notes', 'donor_method','final_annotation_cell_ontology_id'}, inplace=True)\n",
    "\n",
    "#so I can match the SIMBA output dataframe and the 10X object is to use the 10x object index, which I'm calling cell. I have an equivalent column in the SIMBA output dataframe\n",
    "# cell contains the cell barcode along with sample name (short version, doesn't have library lane)\n",
    "alldons_10x.obs['cell'] = alldons_10x.obs.index \n",
    "\n",
    "#going to exclude donors 1 and 2 since they were previously accounted for\n",
    "alldons_10x_don3to16 = alldons_10x[~alldons_10x.obs['donor'].isin(['TSP1', 'TSP2'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the names of cell types to shorten them for plotting purposes\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype']\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('double-positive, alpha-beta thymocyte','alpha-beta thymocyte')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('endothelial cell of artery','artery endo. c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('endothelial cell of vascular tree','vascular endo. c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('endothelial cell of lymphatic vessel','lymph endo.c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('vein endothelial cell','vein endo. c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('skeletal muscle satellite stem cell','skeletal muscle stem c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('capillary endothelial cell','endo. capillary c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('endothelial cell','endo. c.')\n",
    "\n",
    "alldons_10x_don3to16.obs['celltype2']= alldons_10x_don3to16.obs['celltype2'].apply(lambda x: x.replace('cell', 'c.'))\n",
    "alldons_10x_don3to16.obs['celltype2']= alldons_10x_don3to16.obs['celltype2'].str.replace('fibroblast of lung', 'fibroblast')\n",
    "alldons_10x_don3to16.obs['celltype2']= alldons_10x_don3to16.obs['celltype2'].str.replace('pancreatic A c.', 'pancreatic acinar c.')\n",
    "alldons_10x_don3to16.obs['celltype2']= alldons_10x_don3to16.obs['celltype2'].str.replace('pancreatic D c.', 'pancreatic ductal c.')\n",
    "alldons_10x_don3to16.obs['celltype2']= alldons_10x_don3to16.obs['celltype2'].str.replace('double negative thymocyte', 'double neg. thymocyte')\n",
    "alldons_10x_don3to16.obs['celltype2']= alldons_10x_don3to16.obs['celltype2'].str.replace('multi-potent skeletal muscle stem c.', 'skeletal muscle stem c.')\n",
    "alldons_10x_don3to16.obs['celltype2']= alldons_10x_don3to16.obs['celltype2'].str.replace('  ', ' ')\n",
    "\n",
    "alldons_10x_don3to16.obs = alldons_10x_don3to16.obs[~alldons_10x_don3to16.obs['celltype2'].isin(['c.', 'animal c.'])]\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('transit amplifying c. of large intestine', 'transient amplifying c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('transit amplifying c. of small intestine', 'transient amplifying c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('paneth c. of epithelium of small intestine', 'paneth c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('vascular associated smooth muscle c.', 'vasc. smooth muscle c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cd4-positive','cd4+')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cd4-negative', 'cd4-')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cd8-positive','cd8+')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cd8-negative', 'cd8-')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cd1c-positive', 'cd1c+')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cd141-positive', 'cd141+')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cd45ro-positive', 'cd45ro+')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('cytokine secreting ', '')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('memory', 'mem.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('thymus-derived ', '')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('medullary thymic epithelial c.', 'medullary thymic epi. c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('paneth c. of epithelium of large intestine', 'paneth c.')\n",
    "alldons_10x_don3to16.obs['celltype2']=alldons_10x_don3to16.obs['celltype2'].str.replace('serous c. of epithelium of bronchus', 'bronchus serous c.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writing the results of preprocessing of tsp3-16 object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldons_10x_don3to16.write_h5ad(mainDir3 + 'objects/tSP3-16_processed_withCellCycleInfo_09_29_2021-postreview2022.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also saving just the obs layer as a dataframe for easier access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldons_10x_don3to16_obs_df = alldons_10x_don3to16.obs\n",
    "alldons_10x_don3to16_obs_df.to_csv(mainDir10 + 'alldons_10x_don3to16_obs_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging blast datafame with TS object (donors 3-16, excl.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSP3-16 Reading the 10x object obs dataframe that contains all donors and has cell cycle information so that I can merge cellular annotation with SIMBA output\n",
    "will only analyze TSP3-16 (excluding donor 15 because of weird cell type annotations - only contained eye tissue anyway) since processing has already been done for TSP1-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (2,4) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#TS object obs\n",
    "alldons_10x_don3to16_obs_df = pd.read_csv(mainDir10 + 'alldons_10x_don3to16_obs_df.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMBA BLAST processed output\n",
    "final=pd.read_csv(mainDir10 + 'all_batched_and_unbatched_09_09_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of hiv hits: 40354\n"
     ]
    }
   ],
   "source": [
    "hiv_hits = final[final['species'].str.contains('human immuno|Aids', case=False)]\n",
    "print('number of hiv hits:', hiv_hits.shape[0])\n",
    "\n",
    "final2=final[final['species'].str.contains('human immuno|Aids', case=False)==False]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also want to exclude donor 15 due to misannotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldons_10x_don3to16_not15 = alldons_10x_don3to16_obs_df[~alldons_10x_don3to16_obs_df['donor'].isin(['TSP15'])]\n",
    "final_not_tsp15 = final2[~final2['sample'].str.startswith('TSP15')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additionally, i want to make sure there are no more than one significant hit per query sequence in the blast dataset. We go from ~1.5M hits down to ~1.1M. Changing the name of the dataframe from final to blastdb.  Will also change name of alldons_10x_don3to16_not15 (which is the ts object 10X obs layer) to ts_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1468318"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_not_tsp15.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1101511"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blastdb = final_not_tsp15.drop_duplicates('seqName')\n",
    "blastdb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just renaming to something shorter\n",
    "ts_obj = alldons_10x_don3to16_not15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two dataframes only share one column in common called cell. No na values for this column across either of the dataframes, so we can merge the two dataframes on this column.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the TS object donor3-16 excluding 15:  326666\n",
      "size of the BLAST dataframe donor3-16 excluding 15:  1101511\n",
      "size of the intersection:  107744\n"
     ]
    }
   ],
   "source": [
    "print('size of the TS object donor3-16 excluding 15: ', ts_obj.shape[0])\n",
    "print('size of the BLAST dataframe donor3-16 excluding 15: ', blastdb.shape[0])\n",
    "inter = ts_obj.merge(blastdb, on='cell', how='inner')\n",
    "print('size of the intersection: ', inter.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are three categories for the merged blast outputs (blastdb) and TS object (alldons_10x_don3to16_not15).\n",
    "**1) intra** --> annotated cells that have significant **intra**cellular hits \\\n",
    "**2) nothing** --> annotated cells that don't have any significant intracellular hits (based on evalue) \\\n",
    "**3) extra** --> significant hits that are found in either found **extra**cellularly or in unannotated cells. i.e. associated with cellular barcodes. \n",
    "\n",
    "how many of each category is in the dataset (prior to removal of contamination?)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the number of unique hits that are found in annotated cells (category intra):  107744\n",
      "these are the number of unique umis that are found in annotated cells (category intra):  75376\n",
      "number of annotated cells (unique cell barcodes) that have significant hits:  12873\n"
     ]
    }
   ],
   "source": [
    "print('these are the number of unique hits that are found in annotated cells (category intra): ', inter.seqName.nunique())\n",
    "print('these are the number of unique umis that are found in annotated cells (category intra): ', inter.umi.nunique())\n",
    "print('number of annotated cells (unique cell barcodes) that have significant hits: ', inter.cell.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling the blast dataframe by a column called hit: 'yes' and hit_type: 'intra' or 'extra'\n",
    "intra are those hits that were found in annotated cells, and extra are all other hits\n",
    "The cells with no hits will also get hit column=='no'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "tsblast = ts_obj.merge(blastdb, on='cell', how='outer')\n",
    "\n",
    "#these are the hits that are in the \"extra\" category. They don't associate with annotated cells\n",
    "extra=tsblast[tsblast['tissue'].isna()] \n",
    "extra['hit']=extra.shape[0]*['yes']\n",
    "extra['hit_type']=extra.shape[0]*['extra']\n",
    "\n",
    "#these are the hits in the nothing category (i.e. annotated cells without hits)\n",
    "nothing = tsblast[(tsblast['seqName'].isna())] \n",
    "nothing['hit']=['no']* nothing.shape[0]\n",
    "nothing['hit_type']=['none']* nothing.shape[0]\n",
    "\n",
    "#these are the hits in annotated cells\n",
    "intra = tsblast[(tsblast['seqName'].isna()==False) & (tsblast['tissue'].isna()==False)] \n",
    "intra['hit']=['yes']* intra.shape[0]\n",
    "intra['hit_type']=['intra']* intra.shape[0]\n",
    "\n",
    "#lets put together these different pieces now that they have labels with which we can seperate them out again\n",
    "\n",
    "tsblast2=pd.concat([extra, nothing, intra])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "tsblast2['cell_bc'] = tsblast2['10X_barcode'].fillna(tsblast2['cell_bc'])\n",
    "\n",
    "ex  = tsblast2[tsblast2['hit_type']=='extra']\n",
    "other  = tsblast2[tsblast2['hit_type']!='extra']\n",
    "\n",
    "ex['donor'] = ex['sample'].apply(lambda x: x.split('_')[0])\n",
    "ex['tissue'] = ex['sample'].apply(lambda x: x.split('_')[1])\n",
    "tsblast3 = pd.concat([ex, other])\n",
    "\n",
    "\n",
    "tsblast3['tissue'] = tsblast3['tissue'].str.lower()\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('bonemarrow', 'bm'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('bone_marrow', 'bm'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('lymphnode', 'lymph_node'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('lymphnodes', 'lymph_node'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('lymph_nodes', 'lymph_node'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('eye1', 'eye'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('eye2', 'eye'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('eye3', 'eye'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('eye4', 'eye'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('mammary1', 'mammary'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('mammary2', 'mammary'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('exopancreas2', 'pancreas'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('exopancreas1', 'pancreas'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('endopancreas', 'pancreas'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('salivarygland', 'salivary_gland'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('large_intestine', 'li'))\n",
    "tsblast3['tissue'] = tsblast3['tissue'].apply(lambda x: x.replace('small_intestine', 'si'))\n",
    "\n",
    "tsblast3['log2_n_counts']=np.log2(tsblast3['n_counts'])\n",
    "tsblast3['log2_n_genes']=np.log2(tsblast3['n_genes'])\n",
    "\n",
    "tsblast3 = tsblast3.drop(columns={'free_annotation', 'manually_annotated','10X_barcode','Annotation','celltype',\n",
    "                      'Manually Annotated','cycling', 'non-cycling','10X_barcode','anatomical_position',\n",
    "                                 'sample', 'gapopen', 'mismatch', 'method','seqrun'})\n",
    "tsblast3['sample']=tsblast3['sample2'].fillna(tsblast3['sample_short'])\n",
    "\n",
    "tsblast3= tsblast3.drop(columns={'sample_short','sample2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsblast3.to_csv(mainDir10 + 'dons3-16_excluding15_blast_with_cell_annotations-postreview2022.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column name explanation (donor 3-16 excluding 15) final dataframe\n",
    "- Blast dataframe columns (TS object is missing these columns):\n",
    "    - **seqName**: e.g. A00111:327:HL57HDSXX:4:1202:22941:23719_TAGGTCAGAGACATCA_AGAAATAACGCC\n",
    "    - **refName**: the BLAST subject reference gi|1862738216|gb|CP055292.1| \n",
    "    - **pathogen**: common name of the hit \"Shigella sonnei strain SE6-1 chromosome, complete genome\"\n",
    "    - **bitscore**: see BLAST tutorial\n",
    "    - **pident**: percent identity between subject and query\n",
    "    - **evalue**: see BLAST tutorial\n",
    "    - **qstart**: query start position\n",
    "    - **qend**: query end position\n",
    "    -  **sstart**: subject start position\n",
    "    -  **send**: subject end position\n",
    "    -  **length**: length of the alignment between subject and query\n",
    "    - Taxonomy columns \n",
    "        -  **tax_id**: taxonomic id with which we can get the following taxonomic categories\n",
    "        -  **superkingdom**\n",
    "        -  **phylum**\n",
    "        -  **class**\n",
    "        -  **order**\n",
    "        -  **family**\n",
    "        -  **genus**\n",
    "        -  **species**\n",
    "    -  **umi**: AGAAATAACGCC \n",
    "    -  **cell_bc_umi**: cell barcode and umi e.g. TGTCCCATGTACTCTG_CGTTGATACCAC\n",
    "    -  **batch**: this is related to how blast was done for these donors (divided into batches with fixed number of input seqs)\n",
    "    - **filepath**: where the output of the blast resides on my local drive\n",
    "\n",
    "\n",
    "- TS object columns (blast dataframe does not produce these on its own)\n",
    "    - **n_counts**: number of reads per cell\n",
    "    - **n_genes**: number of genes per cell\n",
    "    - **log2_n_counts**: log2 of n_counts\n",
    "    - **log2_n_genes**: log2 of n_genes\n",
    "    - **compartment**: e.g. immune, epithelial\n",
    "    - **decision**: cell cycle decision\n",
    "    - **celltype2**: cell type\n",
    "    - **tissue_cell_type**: tissue and cell type\n",
    "    - **cell_type_tissue**: cell type and tissue\n",
    "\n",
    "\n",
    "- Shared columns:\n",
    "    - **cell**: cell barcode+sample  TGGGCGTGTTGCGCAC_TSP14_Blood_NA_10X_1_1_1_5Prime\n",
    "    - **cell_bc**: cell barcode with \"-1\" appended to it. e.g. CATATTCCAAAGCGGT\n",
    "    - **tissue**: tissue type\n",
    "    - **donor**: donor (e.g. TSP1)\n",
    "    - **sample**: sample name e.g. TSP14_Bladder_NA_10X_1_2\n",
    "    - **hit**: the column with which to seperate out the dataframe into blast (hit=='yes') and ts object (hit=='no')\n",
    "    - **hit_type**: tells us whether the hit comes from an annotated cell (hit_type=='intra'), unannotated cell ('extra') or no hit ('none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's put together the dataframes from ALL donors\n",
    "\n",
    "The two dataframes can be seperated by the column 'donor_batch' donor 1 and 2 \"1_2\", and others \"3_16\"\n",
    "Note, this df hasn't been filtered based on contamination or blast parameters\n",
    "- the columns 'cell_type_tissue', 'cell_bc_umi', 'tissue_cell_type', 'filepath', 'batch' will be null for donors 1 and 2\n",
    "- the column 'seq' will be null for donor 3-16 \n",
    "- the cell column is most useful for counting cells (cell_bc column only contains the cell barcode, and barcodes are used across different samples). \n",
    "- the column cell_bc has 1 appended to it for donor 1-2\n",
    "- as before, both dataframes can be decomposed by \"hit\" and \"hit_type\" columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/gitam/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0,1,2,3,14,15,16,17,18,19,20,22,30,32,34) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/users/gitam/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (4,5,6,7,9,10,11,12,22,23,24,25,26,27,28,29,30,32,33) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fin2= pd.read_csv(mainDir + 'don1_don2_10x_12_08_2022-postreview2022.csv')\n",
    "tsblast3= pd.read_csv(mainDir10 + 'dons3-16_excluding15_blast_with_cell_annotations-postreview2022.csv')\n",
    "\n",
    "\n",
    "fin2['donor_batch']=fin2.shape[0]*['1_2']\n",
    "tsblast3['donor_batch']=tsblast3.shape[0]*['3_16']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns that donors 3-16 dataframe has that the other does not: {'cell_type_tissue', 'cell_bc_umi', 'tissue_cell_type', 'filepath', 'batch'}\n",
      "columns that donors 1-2 dataframe has that the other does not: {'seq'}\n"
     ]
    }
   ],
   "source": [
    "#lets see which columns they share in common (should be most)\n",
    "print('columns that donors 3-16 dataframe has that the other does not:', set(tsblast3.columns) - set(fin2.columns))\n",
    "print('columns that donors 1-2 dataframe has that the other does not:', set(fin2.columns) - set(tsblast3.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "always use cell column (cell bc + sample name) as apposed to cell_bc column which contains just the barcode because the same barcode could be used across different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf=pd.concat([tsblast3,fin2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column name explanation for joined dataframe of ALL donors 1-16 (except 15)\n",
    "- Blast dataframe columns (TS object is missing these columns):\n",
    "    - **seqName**: e.g. A00111:327:HL57HDSXX:4:1202:22941:23719_TAGGTCAGAGACATCA_AGAAATAACGCC\n",
    "    - **seq**: microbial sequence \n",
    "    - **refName**: the BLAST subject reference gi|1862738216|gb|CP055292.1| \n",
    "    - **pathogen**: common name of the hit \"Shigella sonnei strain SE6-1 chromosome, complete genome\"\n",
    "    - **bitscore**: see BLAST tutorial\n",
    "    - **pident**: percent identity between subject and query\n",
    "    - **evalue**: see BLAST tutorial\n",
    "    - **qstart**: query start position\n",
    "    - **qend**: query end position\n",
    "    -  **sstart**: subject start position\n",
    "    -  **send**: subject end position\n",
    "    -  **length**: length of the alignment between subject and query\n",
    "    - Taxonomy columns \n",
    "        -  **tax_id**: taxonomic id with which we can get the following taxonomic categories\n",
    "        -  **superkingdom**\n",
    "        -  **phylum**\n",
    "        -  **class**\n",
    "        -  **order**\n",
    "        -  **family**\n",
    "        -  **genus**\n",
    "        -  **species**\n",
    "    -  **umi**: AGAAATAACGCC \n",
    "    -  **cell_bc_umi**: cell barcode and umi e.g. TGTCCCATGTACTCTG_CGTTGATACCAC\n",
    "    -  **batch**: this is related to how blast was done for these donors (divided into batches with fixed number of input seqs)\n",
    "    - **filepath**: where the output of the blast resides on my local drive\n",
    "\n",
    "\n",
    "- TS object columns (blast dataframe does not produce these on its own)\n",
    "    - **n_counts**: number of reads per cell\n",
    "    - **n_genes**: number of genes per cell\n",
    "    - **log2_n_counts**: log2 of n_counts\n",
    "    - **log2_n_genes**: log2 of n_genes\n",
    "    - **compartment**: e.g. immune, epithelial\n",
    "    - **decision**: cell cycle decision\n",
    "    - **celltype2**: cell type\n",
    "    - **tissue_cell_type**: tissue and cell type\n",
    "    - **cell_type_tissue**: cell type and tissue\n",
    "\n",
    "\n",
    "- Shared columns:\n",
    "    - **cell**: cell barcode+sample  TGGGCGTGTTGCGCAC_TSP14_Blood_NA_10X_1_1_1_5Prime\n",
    "    - **cell_bc**: cell barcode with \"-1\" appended to it. (donor1and2, not for donors 3-16) e.g. CATATTCCAAAGCGGT-1\n",
    "    - **tissue**: tissue type\n",
    "    - **donor**: donor (e.g. TSP1)\n",
    "    - **sample**: sample name e.g. TSP14_Bladder_NA_10X_1_2\n",
    "    - **hit**: the column with which to seperate out the dataframe into blast (hit=='yes') and ts object (hit=='no')\n",
    "    - **hit_type**: tells us whether the hit comes from an annotated cell (hit_type=='intra'), unannotated cell ('extra') or no hit ('none')\n",
    "    - **donor_batch**: donor 1 and 2 dataframe ('1_2'), all others ('3_16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf.to_csv(mainDir10 + 'all_dons_except15_blast_tsobject_postreview.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mainEnv2",
   "language": "python",
   "name": "mainenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "1000px",
    "width": "1081px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "400.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
